{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Case Description\n",
    "\n",
    "### Task Description\n",
    "Basketball tournaments are usually split in two parts. First, all teams play each other aiming to achieve the greatest number of wins possible. Then, at the end of the first part of the season, a pre determined number of teams which were able to win the most games are qualified to the playoff season, where they play series of knock-out matches for the trophy.\n",
    "\n",
    "For the 10 years, data from players, teams, coaches, games and several other metrics were gathered and arranged on this dataset. The goal is to use this data to predict which teams will qualify for the playoffs in the next season.\n",
    "\n",
    "### Data Description\n",
    "The data about the players, teams and coaches consist of following relations:\n",
    "\n",
    "- relation awards_players (96 objects) - each record describes awards and prizes received by players across 10 seasons,\n",
    "- relation coaches (163 objects) - each record describes all coaches who've managed the teams during the time period,\n",
    "- relation players (894 objects) - each record contains details of all players,\n",
    "- relation players_teams (1877 objects) - each record describes the performance of each player for each team they played,\n",
    "- relation series_post (71 objects) - each record describes the series' results,\n",
    "- relation teams (143 objects) - each record describes the performance of the teams for each season,\n",
    "- relation teams_post (81 objects) - each record describes the results of each team at the post-season."
   ],
   "id": "a1e6c20622aba7c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Tables Analysis\n",
    "\n",
    "We started with Exploratory Data Analysis. There are 7 different tables, with different sizes both in lines and columns."
   ],
   "id": "e2042220af2a54f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from utils_cleaning import *",
   "id": "1d70dd947086b47c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Awards Players\n",
    "The first table analysed was awards_players: each record describes awards and prizes received by players across 10 seasons."
   ],
   "id": "5ad5382c0dbc9f1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Read the dataset\n",
    "awards_players_dataSet = pd.read_csv('../Other/basketballPlayoffs/awards_players.csv')"
   ],
   "id": "6c68c396ca9592bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The first approach was to find if there were any missing, duplicate or redundant data:",
   "id": "f20460d597ed5de4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#check if there are null values in the dataset\n",
    "nulls_values_by_column(awards_players_dataSet)\n",
    "\n",
    "#check if there are unique values in the dataset\n",
    "unique_values_by_column(awards_players_dataSet, 1)\n",
    "\n",
    "#remove the column/s that have only one unique value\n",
    "num_columns = len(awards_players_dataSet.columns)\n",
    "awards_players_dataSet = filter_column_uniques(awards_players_dataSet, 1)\n",
    "print(f\"Removed {num_columns - len(awards_players_dataSet.columns)} columns that had only one unique value\")\n",
    "\n",
    "#remove duplicated rows (if present)\n",
    "num_rows = awards_players_dataSet.shape[0]\n",
    "awards_players_dataSet.drop_duplicates(inplace=True)\n",
    "print(f\"Removed {num_rows - awards_players_dataSet.shape[0]} repeated rows\")"
   ],
   "id": "cd0763f3960834bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "We also saw that the same awards table contained both \"Coach of the Year\" and awards regarding only the players.\n",
    "Because of this reason we decided to split the two types of award in two different dataset:"
   ],
   "id": "63e8df44046eac0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "awards_players_dataSet = awards_players_dataSet[awards_players_dataSet.award != 'Kim Perrot Sportsmanship']\n",
    "awards_players_dataSet = awards_players_dataSet[awards_players_dataSet.award != 'Kim Perrot Sportsmanship Award']\n",
    "\n",
    "#We are splitting the awards of the players and the coaches\n",
    "df_coaches = pd.DataFrame(awards_players_dataSet[awards_players_dataSet.award == 'Coach of the Year'])\n",
    "df_coaches.rename(columns={'playerID': 'coachID'}, inplace=True)\n",
    "\n",
    "df_players = pd.DataFrame(awards_players_dataSet[awards_players_dataSet.award != 'Coach of the Year'])"
   ],
   "id": "7fa8265b20dc90d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We saved the two different databases:",
   "id": "e4ff689d07fad2dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_players.to_csv('../newData/awards_players_cleaned.csv', index=False)\n",
    "df_coaches.to_csv('../newData/awards_coaches_cleaned.csv', index=False)"
   ],
   "id": "32c429ca191db0ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Coaches\n",
    "We after studied the coaches dataset: each record describes all coaches who've managed the teams during the time period."
   ],
   "id": "4e37aa1ff78a6b79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "coaches_dataSet = pd.read_csv('../Other/basketballPlayoffs/coaches.csv')",
   "id": "7529e0d57f73eb47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As before we treated the missing, duplicate or redundant data:",
   "id": "265b2701a0f38e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#check if there are null values in the dataset\n",
    "nulls_values_by_column(coaches_dataSet)\n",
    "\n",
    "#check if there are unique values in the dataset\n",
    "unique_values_by_column(coaches_dataSet, 1)\n",
    "\n",
    "#remove the column/s that have only one unique value\n",
    "num_columns = len(coaches_dataSet.columns)\n",
    "coaches_dataSet = filter_column_uniques(coaches_dataSet, 1)\n",
    "print(f\"Removed {num_columns - len(coaches_dataSet.columns)} columns that had only one unique value\")\n",
    "\n",
    "#remove duplicated rows (if present)\n",
    "num_rows = coaches_dataSet.shape[0]\n",
    "coaches_dataSet.drop_duplicates(inplace=True)\n",
    "print(f\"Removed {num_rows - coaches_dataSet.shape[0]} repeated rows\")\n"
   ],
   "id": "dc043ecde93442af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We proceeded to analyze whether were present any outliers and noise:",
   "id": "cf09ef728b472275"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# using the scatterplot to identify the presence of outliers\n",
    "rows_to_drop = set()\n",
    "init_num_rows_coaches = coaches_dataSet.shape[0]\n",
    "\n",
    "scatter_plot(coaches_dataSet.drop(rows_to_drop))\n",
    "\n",
    "print(f\"Founded {len(rows_to_drop)} ({round(len(rows_to_drop) / coaches_dataSet.shape[0] * 100, 1)}%) outliers\")\n",
    "coaches_dataSet.drop(rows_to_drop, axis = 0, inplace=True)\n",
    "print(f\"Removed {init_num_rows_coaches - coaches_dataSet.shape[0]} rows ({round((init_num_rows_coaches - coaches_dataSet.shape[0]) / init_num_rows_coaches * 100, 1)}%)\")"
   ],
   "id": "24711471f17d436e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saving the dataset",
   "id": "8ce699f4e12ec649"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "coaches_dataSet.to_csv('../newData/coaches_cleaned.csv', index=False)",
   "id": "be657d82bea16d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Players\n",
    "Next dataset analysed: each record contains details of all players."
   ],
   "id": "b25ff60f3246b635"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "players_dataSet = pd.read_csv('../Other/basketballPlayoffs/players.csv')",
   "id": "f3399c8ecee0fbad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dealing with missing/duplicate/redundant data",
   "id": "9f58bdfb44a80582"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nulls_values_by_column(players_dataSet)\n",
    "\n",
    "players_dataSet.drop(columns=['collegeOther', 'pos', 'college'], inplace=True, axis=1)\n",
    "\n",
    "unique_values_by_column(players_dataSet, 5)\n",
    "\n",
    "num_columns = len(players_dataSet.columns)\n",
    "players_dataSet = filter_column_uniques(players_dataSet, 5)\n",
    "print(f\"Removed {num_columns - len(players_dataSet.columns)} columns that had only five uniques values\")\n",
    "\n",
    "num_rows = players_dataSet.shape[0]\n",
    "players_dataSet.drop_duplicates(inplace=True)\n",
    "print(f\"Removed {num_rows - players_dataSet.shape[0]} repeated rows\")"
   ],
   "id": "98baa9c802062754",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Analysis of the presence of outliers and noise",
   "id": "7c628c083c612c95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Remove the player still alive\n",
    "players_dataSet = players_dataSet[players_dataSet.birthDate != '0000-00-00']\n",
    "\n",
    "#Remove the player with wrong height\n",
    "players_dataSet = players_dataSet[players_dataSet.height > 10]\n",
    "\n",
    "#Remove the player that have a weight equal to zero\n",
    "players_dataSet = players_dataSet[players_dataSet['weight'] != 0]\n",
    "\n",
    "rows_to_drop = set()\n",
    "init_num_rows_players = players_dataSet.shape[0]\n",
    "\n",
    "scatter_plot(players_dataSet.drop(rows_to_drop, errors='ignore'))\n",
    "print(f\"Founded {len(rows_to_drop)} ({round(len(rows_to_drop) / players_dataSet.shape[0] * 100, 1)}%) outliers\")\n",
    "players_dataSet.drop(rows_to_drop, axis = 0, inplace=True, errors='ignore')\n",
    "print(f\"Removed {init_num_rows_players - players_dataSet.shape[0]} rows ({round((init_num_rows_players - players_dataSet.shape[0]) / init_num_rows_players * 100, 1)}%)\")\n",
    "\n",
    "players_dataSet.columns"
   ],
   "id": "ad23f7fb56ae304a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saving the dataset",
   "id": "10cefeb3b4c2ab05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "players_dataSet.to_csv('../newData/players_cleaned.csv', index=False)",
   "id": "ee8f5d8a9f428e0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Players Teams\n",
    "Next dataset: each record describes the performance of each player for each team they played."
   ],
   "id": "3bdf9f700fbc1171"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "players_teams_dataSet = pd.read_csv('../Other/basketballPlayoffs/players_teams.csv')",
   "id": "fa3bdc0ebaac9db4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As previously dealing with missing/duplicate/redundant data",
   "id": "e81295343400925d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nulls_values_by_column(players_teams_dataSet, (20, 10))\n",
    "\n",
    "unique_values_by_column(players_teams_dataSet, 1, (20,10))\n",
    "\n",
    "num_columns = len(players_teams_dataSet.columns)\n",
    "players_teams_dataSet = filter_column_uniques(players_teams_dataSet, 1)\n",
    "print(f\"Removed {num_columns - len(players_teams_dataSet.columns)} columns that had only one unique value\")\n",
    "\n",
    "num_rows = players_teams_dataSet.shape[0]\n",
    "\n",
    "players_teams_dataSet.drop_duplicates(inplace=True)\n",
    "print(f\"Removed {num_rows - players_teams_dataSet.shape[0]} repeated rows\")"
   ],
   "id": "d45c81174a2b19d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Presence of any outliers and noise",
   "id": "839ca37de94e2425"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_zscore = 3\n",
    "rows2drop = set()\n",
    "histogram_plot(players_teams_dataSet, max_zscore, (24, 100))\n",
    "\n",
    "rows2drop_zscore = filter_by_zscore(players_teams_dataSet, max_zscore)\n",
    "print(f\"Removed {len(rows2drop_zscore)} rows with zscore > {max_zscore}\")\n",
    "\n",
    "rows2drop.update(rows2drop_zscore)"
   ],
   "id": "8940f9c23cc8a83d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saving the dataset",
   "id": "93fbd45d2fedb148"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "players_teams_dataSet.to_csv('../newData/players_teams_cleaned.csv', index=False)",
   "id": "e67552863a80e7b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Series Post\n",
    "Dataset about series post: each record describes the series' results"
   ],
   "id": "a31cd818823c92c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "series_post_dataSet = pd.read_csv('../Other/basketballPlayoffs/series_post.csv')",
   "id": "44331d91c11a0b28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dealing with missing/duplicate/redundant data",
   "id": "7278797646c74305"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nulls_values_by_column(series_post_dataSet)\n",
    "\n",
    "unique_values_by_column(series_post_dataSet, 1)\n",
    "\n",
    "num_columns = len(series_post_dataSet.columns)\n",
    "series_post_dataSet = filter_column_uniques(series_post_dataSet, 1)\n",
    "print(f\"Removed {num_columns - len(series_post_dataSet.columns)} columns that had only one unique value\")\n",
    "\n",
    "num_rows = series_post_dataSet.shape[0]\n",
    "series_post_dataSet.drop_duplicates(inplace=True)\n",
    "print(f\"Removed {num_rows - series_post_dataSet.shape[0]} repeated rows\")"
   ],
   "id": "9b9dace969455331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Treating any outliers and noise:",
   "id": "861c3b1f8e8f603a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rows2drop = set()\n",
    "init_num_rows_series = series_post_dataSet.shape[0]\n",
    "\n",
    "scatter_plot(series_post_dataSet.drop(rows2drop))\n",
    "\n",
    "print(f\"Founded {len(rows2drop)} ({round(len(rows2drop) / series_post_dataSet.shape[0] * 100, 1)}%) outliers\")\n",
    "series_post_dataSet.drop(rows2drop, axis = 0, inplace=True)\n",
    "print(f\"Removed {init_num_rows_series - series_post_dataSet.shape[0]} ({round((init_num_rows_series - series_post_dataSet.shape[0]) / init_num_rows_series * 100, 1)}%) rows\")"
   ],
   "id": "133e27d1403f6c8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saving the dataset",
   "id": "d44e53029331f09e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "series_post_dataSet.to_csv('../newData/series_post_cleaned.csv', index=False)",
   "id": "4b2f6f44fb6ad1d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Teams\n",
    "Dataset about teams: each record describes the performance of the teams for each season."
   ],
   "id": "d8fa29c6fe5b1119"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "teams_dataSet = pd.read_csv('../Other/basketballPlayoffs/teams.csv')",
   "id": "7077cf6895bbe6a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We did the same as the previous datasets: analysis of any missing, duplicate or redundant data",
   "id": "a43baf94d07067ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nulls_values_by_column(teams_dataSet, (20, 10))\n",
    "\n",
    "teams_dataSet.drop([\"divID\"], inplace=True, axis=1)\n",
    "teams_dataSet.fillna(\"N\", inplace=True)\n",
    "\n",
    "unique_values_by_column(teams_dataSet, 1, (20, 10))\n",
    "\n",
    "num_columns = len(teams_dataSet.columns)\n",
    "teams_dataSet = filter_column_uniques(teams_dataSet, 1)\n",
    "print(f\"Removed {num_columns - len(teams_dataSet.columns)} columns that had only one unique value\")\n",
    "\n",
    "num_rows = teams_dataSet.shape[0]\n",
    "teams_dataSet.drop_duplicates(inplace=True)\n",
    "print(f\"Removed {num_rows - teams_dataSet.shape[0]} repeated rows\")"
   ],
   "id": "3e8fe7e40463cb9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Analysis of any outliers and noise.",
   "id": "655e89df6bc7f2b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We saw that in the year 6 there are 2 winners, Connecticut Sun and Sacramento Monarchs. \n",
    "\n",
    "We decided to consider Connecticut Sun as winner"
   ],
   "id": "f014ec727151c308"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# change the winner to False in year 6 team Sacramento Monarchs\n",
    "teams_dataSet.loc[(teams_dataSet[\"year\"] == 6) & (teams_dataSet[\"name\"] == \"Sacramento Monarchs\"), \"finals\"] = \"N\""
   ],
   "id": "40e7cc4bcf15964f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_zscore = 3\n",
    "rows2drop = set()\n",
    "histogram_plot(teams_dataSet, max_zscore, (24, 100))\n",
    "\n",
    "\n",
    "rows2drop_zscore = filter_by_zscore(teams_dataSet, max_zscore, [\"attend\"])\n",
    "print(f\"Removed {len(rows2drop_zscore)} rows with zscore > {max_zscore}\")\n",
    "\n",
    "rows2drop.update(rows2drop_zscore)"
   ],
   "id": "e869bf1f99f97902",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saving dataset",
   "id": "4a794cbd3fe4938a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "teams_EA = teams_dataSet[teams_dataSet['confID'] == 'EA']\n",
    "teams_WE = teams_dataSet[teams_dataSet['confID'] == 'WE']\n",
    "\n",
    "#Split the data for each conference\n",
    "teams_EA.to_csv('../newData/teams_EA_cleaned.csv', index=False)\n",
    "teams_WE.to_csv('../newData/teams_WE_cleaned.csv', index=False)"
   ],
   "id": "7216f33789af0267",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Teams Post\n",
    "In this dataset each record describes the results of each team at the post-season."
   ],
   "id": "f94a8e9eb72e44ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "teams_post_dataSet = pd.read_csv('../Other/basketballPlayoffs/teams_post.csv')",
   "id": "32bb54df90c5364d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dealing with missing/duplicate/redundant data",
   "id": "9d10b8eab41ecedd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nulls_values_by_column(teams_post_dataSet)\n",
    "\n",
    "unique_values_by_column(teams_post_dataSet, 1)\n",
    "\n",
    "num_columns = len(teams_post_dataSet.columns)\n",
    "teams_post_dataSet = filter_column_uniques(teams_post_dataSet, 1)\n",
    "print(f\"Removed {num_columns - len(teams_post_dataSet.columns)} columns that had only one unique value\")\n",
    "\n",
    "num_rows = teams_post_dataSet.shape[0]\n",
    "teams_post_dataSet.drop_duplicates(inplace=True)\n",
    "print(f\"Removed {num_rows - teams_post_dataSet.shape[0]} repeated rows\")"
   ],
   "id": "c83c8c8665dd66cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Study of Outliers and Noise",
   "id": "81b9e59e46ff7834"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_zscore = 3\n",
    "rows2drop = set()\n",
    "histogram_plot(teams_post_dataSet, max_zscore)\n",
    "\n",
    "rows2drop_zscore = filter_by_zscore(teams_post_dataSet, max_zscore, ['L'])\n",
    "print(f\"Removed {len(rows2drop_zscore)} rows with zscore > {max_zscore}\")\n",
    "\n",
    "rows2drop.update(rows2drop_zscore)"
   ],
   "id": "fab98d84f5b694be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saving the dataset",
   "id": "521cdbd12e84ff4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "teams_post_dataSet.to_csv('../newData/teams_post_cleaned.csv', index=False)",
   "id": "96136d1089f397e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Season 11",
   "id": "1aa5927a8882757a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "coaches_11 = pd.read_csv('../../Season_11/coaches.csv')\n",
    "players_teams_11 = pd.read_csv('../../Season_11/players_teams.csv')\n",
    "teams_11 = pd.read_csv('../../Season_11/teams.csv')\n",
    "\n",
    "coaches_11.loc[coaches_11['tmID'] == 'TUL', 'tmID'] = 'DET'\n",
    "\n",
    "teams_11.loc[(teams_11['tmID'] == 'TUL'), ['tmID', 'confID']] = ['DET', 'EA']\n",
    "\n",
    "players_teams_11.loc[players_teams_11['tmID'] == 'TUL', 'tmID'] = 'DET'\n",
    "\n",
    "teams_EA_11 = teams_11[teams_11['confID'] == 'EA']\n",
    "teams_WE_11 = teams_11[teams_11['confID'] == 'WE']\n",
    "\n",
    "#Split the data for each conference\n",
    "teams_EA_11.to_csv('../../Season_11/teams_EA.csv', index=False)\n",
    "teams_WE_11.to_csv('../../Season_11/teams_WE.csv', index=False)\n",
    "\n",
    "coaches = pd.read_csv('../newData/coaches_cleaned.csv')\n",
    "players_teams = pd.read_csv('../newData/players_teams_cleaned.csv')\n",
    "teams_EA = pd.read_csv('../newData/teams_EA_cleaned.csv')\n",
    "teams_WE = pd.read_csv('../newData/teams_WE_cleaned.csv')\n",
    "\n",
    "\n",
    "merged_players_teams = pd.concat([players_teams, players_teams_11], ignore_index=True)\n",
    "filtered_players_teams = merged_players_teams[players_teams.columns]\n",
    "\n",
    "merged_teams_EA = pd.concat([teams_EA, teams_EA_11], ignore_index=True)\n",
    "filtered_teams_EA = merged_teams_EA[teams_EA.columns]\n",
    "\n",
    "merged_teams_WE = pd.concat([teams_WE, teams_WE_11], ignore_index=True)\n",
    "filtered_teams_WE = merged_teams_WE[teams_WE.columns]\n",
    "\n",
    "merged_coaches = pd.concat([coaches, coaches_11], ignore_index=True)\n",
    "filtered_coaches = merged_coaches[coaches.columns]"
   ],
   "id": "a583776a6d280ed9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Players Teams Integration",
   "id": "6cc84f2795ec9d78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "year_11_data = filtered_players_teams[filtered_players_teams['year'] == 11]\n",
    "other_years_data = filtered_players_teams[filtered_players_teams['year'] != 11]\n",
    "\n",
    "player_avg_stats = other_years_data.groupby('playerID').mean(numeric_only=True)\n",
    "\n",
    "team_avg_stats_all_years = other_years_data.groupby('tmID').mean(numeric_only=True)\n",
    "\n",
    "def fill_missing_values_with_team_history(row):\n",
    "    if row['playerID'] in player_avg_stats.index:\n",
    "        player_stats = player_avg_stats.loc[row['playerID']]\n",
    "        row = row.fillna(player_stats)\n",
    "    if row['tmID'] in team_avg_stats_all_years.index:\n",
    "        team_stats = team_avg_stats_all_years.loc[row['tmID']]\n",
    "        row = row.fillna(team_stats)\n",
    "    row = row.fillna(filtered_players_teams.mean(numeric_only=True))\n",
    "    return row\n",
    "\n",
    "year_11_filled_final = year_11_data.apply(fill_missing_values_with_team_history, axis=1)\n",
    "\n",
    "final_dataset_final = pd.concat([other_years_data, year_11_filled_final], ignore_index=True)\n",
    "\n",
    "final_dataset_final.to_csv('../newData/final_players_teams.csv', index=False)"
   ],
   "id": "99257f86e023b63e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Coaches Integration",
   "id": "cb827ed0f508c4e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "year_11_data = filtered_coaches[filtered_coaches['year'] == 11]\n",
    "other_years_data = filtered_coaches[filtered_coaches['year'] != 11]\n",
    "\n",
    "coach_avg_stats = other_years_data.groupby('coachID').mean(numeric_only=True)\n",
    "\n",
    "coach_avg_stats_all_years = other_years_data.groupby('tmID').mean(numeric_only=True)\n",
    "\n",
    "def fill_missing_values_with_team_history(row):\n",
    "    if row['coachID'] in coach_avg_stats.index:\n",
    "        player_stats = coach_avg_stats.loc[row['coachID']]\n",
    "        row = row.fillna(player_stats)\n",
    "    if row['tmID'] in coach_avg_stats_all_years.index:\n",
    "        team_stats = coach_avg_stats_all_years.loc[row['tmID']]\n",
    "        row = row.fillna(team_stats)\n",
    "    row = row.fillna(filtered_coaches.mean(numeric_only=True))\n",
    "    return row\n",
    "\n",
    "year_11_filled_final = year_11_data.apply(fill_missing_values_with_team_history, axis=1)\n",
    "\n",
    "final_dataset_final = pd.concat([other_years_data, year_11_filled_final], ignore_index=True)\n",
    "\n",
    "final_dataset_final.to_csv('../newData/final_coaches.csv', index=False)"
   ],
   "id": "6f8b5a38fc12b456",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Teams East Integration",
   "id": "79c82896290598d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_columns = filtered_teams_EA.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "year_11 = filtered_teams_EA[filtered_teams_EA['year'] == 11]\n",
    "\n",
    "for team in year_11['tmID'].unique():\n",
    "    team_data_past = filtered_teams_EA[(filtered_teams_EA['tmID'] == team) & (filtered_teams_EA['year'] < 11)]\n",
    "    team_means = team_data_past[numeric_columns].mean()\n",
    "    filtered_teams_EA.loc[(filtered_teams_EA['tmID'] == team) & (filtered_teams_EA['year'] == 11), numeric_columns] = \\\n",
    "        filtered_teams_EA[(filtered_teams_EA['tmID'] == team) & (filtered_teams_EA['year'] == 11)][numeric_columns].fillna(team_means)\n",
    "\n",
    "filtered_teams_EA.to_csv('../newData/final_teams_EA.csv', index=False)"
   ],
   "id": "f3476ec7af928139",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Teams West Integration",
   "id": "b9730686db74584f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_columns = filtered_teams_WE.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "year_11 = filtered_teams_WE[filtered_teams_WE['year'] == 11]\n",
    "\n",
    "for team in year_11['tmID'].unique():\n",
    "    team_data_past = filtered_teams_WE[(filtered_teams_WE['tmID'] == team) & (filtered_teams_WE['year'] < 11)]\n",
    "    team_means = team_data_past[numeric_columns].mean()\n",
    "    filtered_teams_WE.loc[(filtered_teams_WE['tmID'] == team) & (filtered_teams_WE['year'] == 11), numeric_columns] = \\\n",
    "        filtered_teams_WE[(filtered_teams_WE['tmID'] == team) & (filtered_teams_WE['year'] == 11)][numeric_columns].fillna(team_means)\n",
    "\n",
    "filtered_teams_WE.to_csv('../newData/final_teams_WE.csv', index=False)"
   ],
   "id": "bde431e407fa3a4f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
